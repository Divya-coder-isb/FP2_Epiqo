# -*- coding: utf-8 -*-
"""Untitled64.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oAod8AG8GBN-PyXr1DBMsErg3LKL_CFv
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import requests
from datetime import datetime, timedelta
from tensorflow.keras.models import load_model
import os

# Function to download files from GitHub
def download_file(url, dest):
    if not os.path.exists(dest):
        response = requests.get(url)
        with open(dest, 'wb') as file:
            file.write(response.content)

# URLs of the model files
xgb_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/xgboost_model.pkl'
lstm_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/lstm_model.h5'
lstm_scaler_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/lstm_scaler.pkl'
svm_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/svm_model.pkl'
svm_scaler_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/svm_scaler.pkl'

# URLs of the images
banner_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/Screenshot%202024-07-03%20135327.png'
bearish_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/Bearish.png'
bullish_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/Bullish.png'

# URL of the historical data
data_url = 'https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/tatamotors_historical_data.csv'

# Download the model files and data
for url, filename in [(xgb_url, 'xgboost_model.pkl'), (lstm_url, 'lstm_model.h5'),
                      (lstm_scaler_url, 'lstm_scaler.pkl'), (svm_url, 'svm_model.pkl'),
                      (svm_scaler_url, 'svm_scaler.pkl'), (banner_url, 'banner.png'),
                      (bearish_url, 'bearish.png'), (bullish_url, 'bullish.png'),
                      (data_url, 'tatamotors_historical_data.csv')]:
    download_file(url, filename)

# Load models and scalers
@st.cache(allow_output_mutation=True)
def load_models():
    xgb_model = joblib.load('xgboost_model.pkl')
    lstm_model = load_model('lstm_model.h5')
    lstm_scaler = joblib.load('lstm_scaler.pkl')
    svm_model = joblib.load('svm_model.pkl')
    svm_scaler = joblib.load('svm_scaler.pkl')
    return xgb_model, lstm_model, lstm_scaler, svm_model, svm_scaler

# Load the historical data
@st.cache(allow_output_mutation=True)
def load_data():
    df = pd.read_csv('tatamotors_historical_data.csv')
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %H:%M:%S%z', utc=True)
    df.set_index('Date', inplace=True)
    return df

xgb_model, lstm_model, lstm_scaler, svm_model, svm_scaler = load_models()
df = load_data()

# Ensure feature names match
expected_features = xgb_model.feature_names_in_

# Helper functions
def create_features(df):
    df['dayofweek'] = df.index.dayofweek
    df['quarter'] = df.index.quarter
    df['month'] = df.index.month
    df['year'] = df.index.year
    df['dayofyear'] = df.index.dayofyear
    df['dayofmonth'] = df.index.day
    df['weekofyear'] = df.index.isocalendar().week

    if len(df) > 7:
        df['lag_1'] = df['Close'].shift(1)
        df['lag_2'] = df['Close'].shift(2)
        df['lag_3'] = df['Close'].shift(3)
        df['rolling_mean_3'] = df['Close'].rolling(window=3).mean()
        df['rolling_std_3'] = df['Close'].rolling(window=3).std()
        df['rolling_mean_7'] = df['Close'].rolling(window=7).mean()
        df['rolling_std_7'] = df['Close'].rolling(window=7).std()

    return df.dropna()  # Drop rows where any of the elements is nan

df = create_features(df)

def calculate_rsi(data, window=14):
    delta = data.diff()
    gain = (delta.where(delta > 0, 0)).fillna(0)
    loss = (-delta.where(delta < 0, 0)).fillna(0)
    avg_gain = gain.rolling(window=window, min_periods=1).mean()
    avg_loss = loss.rolling(window=window, min_periods=1).mean()
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

def classify_trend(date):
    temp_df = pd.DataFrame([{'Date': date}])
    temp_df.set_index('Date', inplace=True)
    temp_df['Close'] = np.nan  # Add a dummy Close value to avoid errors in RSI calculation
    combined_df = pd.concat([df, temp_df])
    combined_df['Close'].interpolate(inplace=True)  # Interpolate missing Close values
    rsi = calculate_rsi(combined_df['Close']).iloc[-1]
    rsi_scaled = svm_scaler.transform([[rsi]])
    trend = svm_model.predict(rsi_scaled)[0]
    return trend

def forecast(date, today):
    if (date - today).days < 90:
        features = create_date_features(date, df)
        prediction = xgb_model.predict(features)[0]
    else:
        seq_length = 60  # Ensure this matches the training sequence length
        # Generate future dates starting from the last available date in the data
        last_available_date = df.index[-1]
        future_dates = pd.date_range(start=last_available_date + timedelta(days=1), end=date, freq='B', tz='UTC')
        future_df = pd.DataFrame(index=future_dates)
        future_df['Close'] = np.nan

        # Combine with existing data and interpolate
        combined_df = pd.concat([df, future_df])
        combined_df['Close'].interpolate(method='linear', inplace=True)  # Ensure this method was used in training

        # Debug: Output combined DataFrame to check correctness
        st.write("Combined DataFrame for LSTM input:", combined_df.tail(60))

        # Select the most recent sequence for prediction
        recent_data = combined_df[['Close']].iloc[-seq_length:].to_numpy()

        # Scale the data as was done in training
        scaled_data = lstm_scaler.transform(recent_data.reshape(-1, 1))
        scaled_data = scaled_data.reshape(1, seq_length, 1)  # Reshape for LSTM (batch_size, seq_length, num_features)

        # Predict and inverse scale
        prediction = lstm_model.predict(scaled_data)
        prediction = lstm_scaler.inverse_transform(prediction)[0][0]

        # Debug: Log the LSTM prediction
        st.write("LSTM prediction for long-term:", prediction)

    return prediction

# Streamlit UI setup
st.image(banner_image)
st.write("""
# Tata Motors Limited (TATAMOTORS.NS)
It offers its products to fleet owners, transporters, government agencies, defense, public transport utilities, small and medium enterprises (SMEs), agriculture and rural segment, mining and construction industry, etc. The company was incorporated in 1945 and is headquartered in Mumbai, India.
""")

selected_date = st.date_input("Select a date", min_value=datetime.now().date(), max_value=datetime.now().date() + timedelta(days=365))
user_date = pd.to_datetime(selected_date).tz_localize('UTC')

if user_date.weekday() >= 5:
    st.error("Select trading days only")
else:
    today = pd.to_datetime('today').tz_localize('UTC')
    if st.button('Apply'):
        trend = classify_trend(user_date)
        forecast_price = forecast(user_date, today)
        st.write(f"### Forecast Price: {forecast_price}")
        if trend == 'bearish':
            st.image(bearish_image, caption='Bearish Trend')
        elif trend == 'bullish':
            st.image(bullish_image, caption='Bullish Trend')
        else:
            st.write("### Neutral")