# -*- coding: utf-8 -*-
"""Untitled64.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oAod8AG8GBN-PyXr1DBMsErg3LKL_CFv
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import requests
from datetime import datetime, timedelta
from tensorflow.keras.models import load_model
import os

# Function to download files from GitHub safely
def download_file(url, dest):
    if not os.path.exists(dest):
        response = requests.get(url)
        if response.status_code == 200:
            with open(dest, 'wb') as file:
                file.write(response.content)
        else:
            st.error("Failed to download data: " + url)
            return False
    return True

# Download and load all necessary resources
files_to_download = {
    "xgb_model": "https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/xgboost_model.pkl",
    "lstm_model": "https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/lstm_model.h5",
    "lstm_scaler": "https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/lstm_scaler.pkl",
    "svm_model": "https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/svm_model.pkl",
    "svm_scaler": "https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/svm_scaler.pkl",
    "data": "https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/tatamotors_historical_data.csv"
}

for dest, url in files_to_download.items():
    if not download_file(url, dest):
        st.stop()

xgb_model = joblib.load('xgb_model')
lstm_model = load_model('lstm_model')
lstm_scaler = joblib.load('lstm_scaler')
svm_model = joblib.load('svm_model')
svm_scaler = joblib.load('svm_scaler')

df = pd.read_csv('data')
df['Date'] = pd.to_datetime(df['Date'])  # Let pandas infer the format
df.set_index('Date', inplace=True)

# Function to create features
def create_features(df):
    df['lag_1'] = df['Close'].shift(1)
    df['lag_2'] = df['Close'].shift(2)
    df['lag_3'] = df['Close'].shift(3)
    df['rolling_mean_3'] = df['Close'].rolling(window=3).mean()
    df['rolling_std_3'] = df['Close'].rolling(window=3).std()
    df['rolling_mean_7'] = df['Close'].rolling(window=7).mean()
    df['rolling_std_7'] = df['Close'].rolling(window=7).std()
    return df.dropna()

df = create_features(df)

# Function to create features for a single date
def create_date_features(date, df):
    try:
        last_row = df.iloc[-1].copy()
        last_row.name = date
        return last_row.to_frame().transpose()
    except Exception as e:
        st.error("Failed to create date features: " + str(e))
        return None

# Function to handle RSI calculation
def calculate_rsi(series, window=14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).fillna(0)
    loss = (-delta.where(delta < 0, 0)).fillna(0)
    avg_gain = gain.rolling(window=window, min_periods=1).mean()
    avg_loss = loss.rolling(window=window, min_periods=1).mean()
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

# Classify the trend
def classify_trend(date):
    features = create_date_features(date, df)
    if features is not None:
        rsi = calculate_rsi(df['Close']).iloc[-1]
        rsi_scaled = svm_scaler.transform([[rsi]])
        return svm_model.predict(rsi_scaled)[0]
    else:
        return "neutral"

# Forecast function integrating LSTM for long-term forecasts
def forecast(date, today):
    if (date - today).days < 90:
        features = create_date_features(date, df)
        if features is not None:
            features_array = features.values
            prediction = xgb_model.predict(features_array)[0]
        else:
            prediction = "No available data to predict"
    else:
        prediction = lstm_forecast(date)
    return prediction

# LSTM forecasting placeholder
def lstm_forecast(date):
    seq_length = 60  # Assuming 60-day sequences for LSTM
    future_dates = pd.date_range(start=df.index[-1] + timedelta(days=1), end=date, freq='B')
    future_df = pd.DataFrame(index=future_dates)
    future_df['Close'] = np.nan
    combined_df = pd.concat([df, future_df])
    combined_df['Close'].interpolate(method='linear', inplace=True)

    recent_data = combined_df[['Close']].iloc[-seq_length:].values
    scaled_data = lstm_scaler.transform(recent_data)
    scaled_data = scaled_data.reshape(1, seq_length, 1)

    prediction = lstm_model.predict(scaled_data)
    prediction = lstm_scaler.inverse_transform(prediction)[0][0]
    return prediction

# UI setup
st.image('https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/Screenshot%202024-07-03%20135327.png')
st.title("Tata Motors Limited (TATAMOTORS.NS)")

selected_date = st.date_input("Select a date", min_value=datetime.now().date(), max_value=datetime.now().date() + timedelta(days=365))
user_date = pd.to_datetime(selected_date).tz_localize('UTC')

if user_date.weekday() >= 5:
    st.error("Select trading days only.")
else:
    today = pd.to_datetime('today').tz_localize('UTC')
    if st.button('Apply'):
        trend = classify_trend(user_date)
        forecast_price = forecast(user_date, today)
        st.write(f"### Forecast Price: {forecast_price}")
        trend_image = 'bearish' if trend == 'bearish' else 'bullish'
        st.image('https://github.com/Divya-coder-isb/FP2_Epiqo/raw/main/' + trend_image + '.png', caption='Trend Prediction')